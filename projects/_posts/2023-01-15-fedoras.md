---
layout: post
title: >
    FedorAS: Federated Architecture Search under system heterogeneity
description: >
  Federated learning (FL) has recently gained considerable attention due to its ability to learn on decentralised data while preserving client privacy. However, it also poses additional challenges related to the heterogeneity of the participating devices, both in terms of their computational capabilities and contributed data. Meanwhile, Neural Architecture Search (NAS) has been successfully used with centralised datasets, producing state-of-the-art results in constrained or unconstrained settings. However, such centralised datasets may not be always available for training. Most recent work at the intersection of NAS and FL attempts to alleviate this issue in a cross-silo federated setting, which assumes homogeneous compute environments with datacenter-grade hardware. In this paper we explore the question of whether we can design architectures of different footprints in a cross-device federated setting, where the device landscape, availability and scale are very different. To this end, we design our system, FedorAS, to discover and train promising architectures in a resource-aware manner when dealing with devices of varying capabilities holding non-IID distributed data. We present empirical evidence of its effectiveness across different settings, spanning across three different modalities (vision, speech, text), and showcase its better performance compared to state-of-the-art federated solutions, while maintaining resource efficiency.
accent_image:
  background: url('/assets/img/blog/research.jpg') top/cover
  overlay: true
invert_sidebar: false
sitemap: false
hide_last_modified: true
---

**Authors:** Lukasz Dudziak, **Stefanos Laskaridis**, Javier Fernandez-Marques

**Published at:** _International Workshop on Federated Learning: Recent Advances and New Challenges
in Conjunction with NeurIPS 2022 (FL-NeurIPS'22)_ (short paper)

## Overview

![FedorAS](/assets/img/blog/fedoras/fedoras-poster.png)

With FedorAS, we tackled the problem of neural architecture search in cross-device federated learning, where clients differ widely in compute, memory, and data distribution. We built a federated NAS framework that is explicitly resource-aware and robust to non-IID data.

Across vision, speech, and language tasks, FedorAS discovers architectures that outperform existing federated baselines while respecting client constraints. This work shows that architecture search can be practical and effective even in highly heterogeneous federated settings.


## Links

* [preprint](https://arxiv.org/abs/2206.11239)
* [short paper](https://openreview.net/forum?id=C1NtSM4Q4i3)
* [code](https://github.com/SamsungLabs/FedorAS)